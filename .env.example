# Environment Configuration Template
# Copy this file to .env and update with your values

# LLM Configuration
# Ollama server URL - default is local instance
OLLAMA_BASE_URL=http://localhost:11434
# Model:llama3.1 
OLLAMA_MODEL=llama3.1:8b

# LangSmith Configuration
# Enable LangSmith tracing for observability and debugging
LANGCHAIN_TRACING_V2=true
# LangSmith API key - get from https://smith.langchain.com/
LANGCHAIN_API_KEY=your_langsmith_api_key_here
# Project name in LangSmith dashboard
LANGCHAIN_PROJECT=procurement-agent

# Data Configuration
# Path to the dataset directory (relative or absolute)
DATA_PATH=Agents - Code Challenge/Data/
